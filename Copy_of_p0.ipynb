{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQP-HfSMt-Mi"
      },
      "source": [
        "# MLDS/DiRP Reading Group Project 0: Neural Network Regression\n",
        "\n",
        "For this project, you will writing a neural network using PyTorch. You will be predicting house values in California using the California Housing Prices dataset.\n",
        "\n",
        "### Getting Started: Google Colab\n",
        "\n",
        "On Google Colab, click connect and start running cells. All the necessary packages are pre-installed.\n",
        "\n",
        "### Getting Started: Local\n",
        "\n",
        "To run this project locally with conda, run the following commands:\n",
        "\n",
        "``` bash\n",
        "conda create -n reading_group python==3.10.13\n",
        "conda activate reading_group\n",
        "pip install torch\n",
        "pip install scikit-learn\n",
        "pip install juptyerlab\n",
        "```\n",
        "\n",
        "If you do not have conda, you can install the VSCode Extension `Python Environment Manager`, then it should prompt you to install conda.\n",
        "\n",
        "### Project Tasks\n",
        "\n",
        "1. Implement the `MLP` class\n",
        "2. Define the `criterion` and `optimizer` variables\n",
        "3. Experiment with different hyperparameters to get the best test loss\n",
        "\n",
        "### Bonus Tasks\n",
        "\n",
        "1. Add GPU support\n",
        "2. Implement checkpointing\n",
        "3. Implement a learning rate scheduler\n",
        "4. Implement early stopping\n",
        "5. Download the iris dataset using `load_iris` and train a classifier instead of a regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRTXQpost-Mm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from sklearn.datasets import fetch_california_housing, load_iris\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWuRsbYQt-Mn"
      },
      "outputs": [],
      "source": [
        "# Multi-layer perceptron\n",
        "# import torch.nn as nn\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        \"\"\"Define layers here\"\"\"\n",
        "        super().__init__()\n",
        "        self.l0=nn.Linear(input_size, 512)\n",
        "        self.bn0=nn.BatchNorm1d(512)\n",
        "        self.d0 = nn.Dropout(0.1)\n",
        "        self.relu0 = nn.ReLU()\n",
        "\n",
        "        self.l1=nn.Linear(512, 512)\n",
        "        self.bn1=nn.BatchNorm1d(512)\n",
        "        self.d1 = nn.Dropout(0.1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.l2=nn.Linear(512,512)\n",
        "        self.bn2=nn.BatchNorm1d(512)\n",
        "        self.d2 = nn.Dropout(0.1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.l3=nn.Linear(512, 512)\n",
        "        self.bn3=nn.BatchNorm1d(512)\n",
        "        self.d3 = nn.Dropout(0.1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.l4=nn.Linear(512,512)\n",
        "        self.bn4=nn.BatchNorm1d(512)\n",
        "        self.d4 = nn.Dropout(0.1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.l5=nn.Linear(512, 512)\n",
        "        self.bn5=nn.BatchNorm1d(512)\n",
        "        self.d5 = nn.Dropout(0.1)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "        self.l6=nn.Linear(512, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x : Tensor) -> Tensor:\n",
        "        \"\"\"Use layers here\n",
        "        Input dimension: (batch_size, 8)\n",
        "        Output dimension: (batch_size, 1)\"\"\"\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        x = self.relu0(self.d0(self.bn0(self.l0(x))))\n",
        "        x = self.relu1(self.d1(self.bn1(self.l1(x))))\n",
        "        x = self.relu2(self.d2(self.bn2(self.l2(x))))\n",
        "        x = self.relu3(self.d3(self.bn3(self.l3(x))))\n",
        "        x = self.relu4(self.d4(self.bn4(self.l4(x))))\n",
        "        x = self.relu5(self.d5(self.bn5(self.l5(x))))\n",
        "        x=self.l6(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlMW7RSat-Mn",
        "outputId": "13439b83-2cc8-401b-86cf-2476955eabbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape torch.Size([20640, 8])\n",
            "target shape torch.Size([20640])\n",
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 20640\n",
            "\n",
            ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            ":Attribute Information:\n",
            "    - MedInc        median income in block group\n",
            "    - HouseAge      median house age in block group\n",
            "    - AveRooms      average number of rooms per household\n",
            "    - AveBedrms     average number of bedrooms per household\n",
            "    - Population    block group population\n",
            "    - AveOccup      average number of household members\n",
            "    - Latitude      block group latitude\n",
            "    - Longitude     block group longitude\n",
            "\n",
            ":Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
            "\n",
            "The target variable is the median house value for California districts,\n",
            "expressed in hundreds of thousands of dollars ($100,000).\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "A household is a group of people residing within a home. Since the average\n",
            "number of rooms and bedrooms in this dataset are provided per household, these\n",
            "columns may take surprisingly large values for block groups with few households\n",
            "and many empty houses, such as vacation resorts.\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. rubric:: References\n",
            "\n",
            "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "  Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Load the Boston housing dataset\n",
        "data = fetch_california_housing()\n",
        "inputs = data.data\n",
        "targets = data.target\n",
        "\n",
        "# Convert the data to tensors\n",
        "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
        "targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "# Normalize the data\n",
        "mean = inputs.mean(dim=0, keepdim=True)\n",
        "std = inputs.std(dim=0, keepdim=True)\n",
        "inputs = (inputs - mean) / std\n",
        "\n",
        "mean = targets.mean(dim=0, keepdim=True)\n",
        "std = targets.std(dim=0, keepdim=True)\n",
        "targets = (targets - mean) / std\n",
        "\n",
        "print(\"input shape\", inputs.shape)\n",
        "print(\"target shape\", targets.shape)\n",
        "print(data.DESCR)\n",
        "\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(42))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "# Create the MLP model\n",
        "model = MLP(8)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9-D2xLTt-Mn",
        "outputId": "628d4f49-e8fe-471f-a49a-7ce129e20f66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 0.006316485108708489, Val Loss: 0.044018701638704465, Test Loss: 0.03737354977631275\n",
            "Epoch 19, Train Loss: 0.0063645071108665695, Val Loss: 0.043125401676437, Test Loss: 0.03692822986178928\n",
            "Epoch 29, Train Loss: 0.006230036845574012, Val Loss: 0.045073549136703396, Test Loss: 0.03701156157034415\n",
            "Epoch 39, Train Loss: 0.006140389125022662, Val Loss: 0.04157633122838574, Test Loss: 0.036062419414520264\n",
            "Stopping early at epoch 45\n",
            "Best Epoch: 25, Train Loss: 0.407353, Val Loss: 0.366158, Test Loss: 0.328740\n"
          ]
        }
      ],
      "source": [
        "best_train_loss = float(\"inf\")\n",
        "best_val_loss = float(\"inf\")\n",
        "best_test_loss = float(\"inf\")\n",
        "best_epoch = 0\n",
        "# Train the model\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, targets in train_dataloader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.flatten(), targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for inputs, targets in val_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.flatten(), targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        # Test the model\n",
        "        test_loss = 0.0\n",
        "        for inputs, targets in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.flatten(), targets)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    val_loss /= len(val_dataloader)\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Train Loss: {train_loss / len(train_dataloader)}, Val Loss: {val_loss / len(val_dataloader)}, Test Loss: {test_loss / len(test_dataloader)}\")\n",
        "\n",
        "\n",
        "    # Checkpoint the best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_train_loss = train_loss\n",
        "        best_val_loss = val_loss\n",
        "        best_test_loss = test_loss\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), \"best.pt\")\n",
        "\n",
        "    # Early stopping\n",
        "    if epoch - best_epoch >= 20:\n",
        "        print(f\"Stopping early at epoch {epoch}\")\n",
        "        print(\n",
        "            f\"Best Epoch: {best_epoch}, Train Loss: {best_train_loss:4f}, Val Loss: {best_val_loss:4f}, Test Loss: {best_test_loss:4f}\"\n",
        "        )\n",
        "        break\n",
        "\n",
        "    # Update the LR\n",
        "    scheduler.step()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "reading_group",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}